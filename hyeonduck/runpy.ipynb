{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24917,
     "status": "ok",
     "timestamp": 1630293803468,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "mIg0yvPACVZH",
    "outputId": "818549f2-54c2-46e2-f31a-87a17cd33950"
   },
   "outputs": [],
   "source": [
    "# google drive import\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9533,
     "status": "ok",
     "timestamp": 1630283721167,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "2Gzoni_aCaP9",
    "outputId": "ac073834-933f-41d1-8c65-de47d9a0bdf4"
   },
   "outputs": [],
   "source": [
    "##dotenv 설치\n",
    "#!pip install dotenv-python\n",
    "#!pip install colab-env --upgrade\n",
    "#!pip install transformers\n",
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1630283729592,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "_kh7IVYhjREM",
    "outputId": "817907a0-4454-4df2-f98c-8c142a3132d4"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YTNVmlzD8et"
   },
   "outputs": [],
   "source": [
    "#압축 풀기\n",
    "#!tar -xvf \"train.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1630239924250,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "GwilKR6LHm4j",
    "outputId": "9fdda530-d6c9-4cdc-832a-976339733cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimson\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-snowball-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/simson/13AI\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/simson/13AI/runs/3k3tq65w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /opt/ml/input/data/wandb/run-20210831_081655-3k3tq65w\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "usage: train.py [-h] [--seed SEED] [--epochs EPOCHS] [--dataset DATASET]\n",
      "                [--augmentation AUGMENTATION] [--resize RESIZE [RESIZE ...]]\n",
      "                [--batch_size BATCH_SIZE]\n",
      "                [--valid_batch_size VALID_BATCH_SIZE] [--model MODEL]\n",
      "                [--optimizer OPTIMIZER] [--lr LR] [--val_ratio VAL_RATIO]\n",
      "                [--criterion CRITERION] [--lr_decay_step LR_DECAY_STEP]\n",
      "                [--log_interval LOG_INTERVAL] [--name NAME]\n",
      "                [--data_dir DATA_DIR] [--model_dir MODEL_DIR]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --seed SEED           random seed (default: 42)\n",
      "  --epochs EPOCHS       number of epochs to train (default: 1)\n",
      "  --dataset DATASET     dataset augmentation type (default: MaskBaseDataset)\n",
      "  --augmentation AUGMENTATION\n",
      "                        data augmentation type (default: BaseAugmentation)\n",
      "  --resize RESIZE [RESIZE ...]\n",
      "                        resize size for image when training\n",
      "  --batch_size BATCH_SIZE\n",
      "                        input batch size for training (default: 64)\n",
      "  --valid_batch_size VALID_BATCH_SIZE\n",
      "                        input batch size for validing (default: 1000)\n",
      "  --model MODEL         model type (default: BaseModel)\n",
      "  --optimizer OPTIMIZER\n",
      "                        optimizer type (default: SGD)\n",
      "  --lr LR               learning rate (default: 1e-3)\n",
      "  --val_ratio VAL_RATIO\n",
      "                        ratio for validaton (default: 0.1)\n",
      "  --criterion CRITERION\n",
      "                        criterion type (default: cross_entropy)\n",
      "  --lr_decay_step LR_DECAY_STEP\n",
      "                        learning rate scheduler deacy step (default: 20)\n",
      "  --log_interval LOG_INTERVAL\n",
      "                        how many batches to wait before logging training\n",
      "                        status\n",
      "  --name NAME           model save at {SM_MODEL_DIR}/{name}\n",
      "  --data_dir DATA_DIR\n",
      "  --model_dir MODEL_DIR\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 17928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /opt/ml/input/data/wandb/run-20210831_081655-3k3tq65w/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /opt/ml/input/data/wandb/run-20210831_081655-3k3tq65w/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mworldly-snowball-2\u001b[0m: \u001b[34mhttps://wandb.ai/simson/13AI/runs/3k3tq65w\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py  --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9322671,
     "status": "ok",
     "timestamp": 1630261529775,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "bSmdM8bCIdb3",
    "outputId": "be93d709-d003-45f3-81f3-a42055b13a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimson\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-cherry-30\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/13ai/hd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/13ai/hd/runs/3gvhda9v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /opt/ml/input/data/wandb/run-20210831_165336-3gvhda9v\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Namespace(augmentation='BaseAugmentation', batch_size=32, criterion='cross_entropy', data_dir='train/images', dataset='MaskBaseDataset', epochs=100, log_interval=20, lr=0.001, lr_decay_step=5, model='resnext', model_dir='./model', name='exp', optimizer='Adam', resize=[112, 112], seed=42, val_ratio=0.1, valid_batch_size=1000)\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% |  2% |\n",
      "Epoch[0/100](20/472) || training loss 2.943 || training accuracy 19.84% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 25% |\n",
      "Epoch[0/100](40/472) || training loss 2.613 || training accuracy 18.91% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 91% | 25% |\n",
      "Epoch[0/100](60/472) || training loss 2.345 || training accuracy 22.81% || lr 0.001\n",
      "Epoch[0/100](80/472) || training loss 2.228 || training accuracy 24.22% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 22% | 25% |\n",
      "Epoch[0/100](100/472) || training loss 2.159 || training accuracy 29.69% || lr 0.001\n",
      "Epoch[0/100](120/472) || training loss 2.073 || training accuracy 27.50% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 25% |\n",
      "Epoch[0/100](140/472) || training loss 1.938 || training accuracy 34.53% || lr 0.001\n",
      "Epoch[0/100](160/472) || training loss 1.907 || training accuracy 30.78% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 25% |\n",
      "Epoch[0/100](180/472) || training loss 1.919 || training accuracy 35.47% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 25% |\n",
      "Epoch[0/100](200/472) || training loss 1.881 || training accuracy 36.88% || lr 0.001\n",
      "Epoch[0/100](220/472) || training loss 1.867 || training accuracy 34.69% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 69% | 25% |\n",
      "Epoch[0/100](240/472) || training loss 1.871 || training accuracy 35.16% || lr 0.001\n",
      "Epoch[0/100](260/472) || training loss 1.77 || training accuracy 39.06% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 41% | 25% |\n",
      "Epoch[0/100](280/472) || training loss 1.796 || training accuracy 39.84% || lr 0.001\n",
      "Epoch[0/100](300/472) || training loss 1.688 || training accuracy 43.59% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 25% |\n",
      "Epoch[0/100](320/472) || training loss 1.729 || training accuracy 39.22% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 25% |\n",
      "Epoch[0/100](340/472) || training loss 1.666 || training accuracy 44.06% || lr 0.001\n",
      "Epoch[0/100](360/472) || training loss 1.724 || training accuracy 44.22% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 60% | 25% |\n",
      "Epoch[0/100](380/472) || training loss 1.684 || training accuracy 41.25% || lr 0.001\n",
      "Epoch[0/100](400/472) || training loss 1.64 || training accuracy 44.84% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 84% | 25% |\n",
      "Epoch[0/100](420/472) || training loss 1.48 || training accuracy 50.94% || lr 0.001\n",
      "Epoch[0/100](440/472) || training loss 1.522 || training accuracy 51.56% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 62% | 25% |\n",
      "Epoch[0/100](460/472) || training loss 1.589 || training accuracy 49.06% || lr 0.001\n",
      "Calculating validation results...\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 25% |\n",
      "New best model for val accuracy : 33.15%! saving the best model..\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 55% | 63% |\n",
      "[Val] acc : 33.15%, loss:  1.7 || best acc : 33.15%, best loss:  1.7\n",
      "\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 48% | 63% |\n",
      "Epoch[1/100](20/472) || training loss 1.418 || training accuracy 50.94% || lr 0.001\n",
      "Epoch[1/100](40/472) || training loss 1.415 || training accuracy 53.28% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 63% |\n",
      "Epoch[1/100](60/472) || training loss 1.496 || training accuracy 49.53% || lr 0.001\n",
      "Epoch[1/100](80/472) || training loss 1.372 || training accuracy 52.50% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 63% |\n",
      "Epoch[1/100](100/472) || training loss 1.323 || training accuracy 56.41% || lr 0.001\n",
      "Epoch[1/100](120/472) || training loss 1.32 || training accuracy 55.62% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 75% | 63% |\n",
      "Epoch[1/100](140/472) || training loss 1.391 || training accuracy 55.47% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 63% |\n",
      "Epoch[1/100](160/472) || training loss 1.225 || training accuracy 59.84% || lr 0.001\n",
      "Epoch[1/100](180/472) || training loss 1.298 || training accuracy 58.44% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 72% | 63% |\n",
      "Epoch[1/100](200/472) || training loss 1.232 || training accuracy 60.16% || lr 0.001\n",
      "Epoch[1/100](220/472) || training loss 1.155 || training accuracy 62.66% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 63% |\n",
      "Epoch[1/100](240/472) || training loss 1.297 || training accuracy 59.69% || lr 0.001\n",
      "Epoch[1/100](260/472) || training loss 1.255 || training accuracy 56.72% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 95% | 63% |\n",
      "Epoch[1/100](280/472) || training loss 1.185 || training accuracy 61.09% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 86% | 63% |\n",
      "Epoch[1/100](300/472) || training loss 1.211 || training accuracy 60.31% || lr 0.001\n",
      "Epoch[1/100](320/472) || training loss 1.156 || training accuracy 62.19% || lr 0.001\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 89% | 63% |\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "python train.py  --data_dir train/images --model resnext --epochs 100 --optimizer Adam --batch_size 32\n",
    "'''\n",
    "!python train.py  --data_dir train/images --model resnext --epochs 100 --optimizer Adam --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1302,
     "status": "ok",
     "timestamp": 1630246710942,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "uCfgEODLO8-K",
    "outputId": "1a3811b1-f1a7-4615-f7cf-ffdc96a97459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: inference.py [-h] [--batch_size BATCH_SIZE] [--resize RESIZE]\n",
      "                    [--model MODEL] [--data_dir DATA_DIR]\n",
      "                    [--model_dir MODEL_DIR] [--output_dir OUTPUT_DIR]\n",
      "inference.py: error: argument -h/--help: ignored explicit argument 'elp'\n"
     ]
    }
   ],
   "source": [
    "!python inference.py -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375789,
     "status": "ok",
     "timestamp": 1630286215398,
     "user": {
      "displayName": "kong king",
      "photoUrl": "",
      "userId": "00306219203767874913"
     },
     "user_tz": -540
    },
    "id": "Xe91UUS-Qf3D",
    "outputId": "e2ff2441-0a1e-4148-d52a-816959de90be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"inference.py\", line 9, in <module>\n",
      "    from dataset import TestDataset, MaskBaseDataset\n",
      "  File \"/opt/ml/input/data/dataset.py\", line 107\n",
      "    return co(self.transform(image))\n",
      "                                   ^\n",
      "IndentationError: unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "!python inference.py   --model_dir model/exp  --model resnext"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgyxEH04/vWdxA0bSdIkV3",
   "name": "runpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
