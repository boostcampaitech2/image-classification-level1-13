{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5680af35-ac7e-4786-9244-e6400a1927c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Conv2d, AdaptiveAvgPool2d, ReLU, Linear, Softmax\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113d3755-88fa-4384-b285-8b22fa1bcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc3eef-54e4-42d0-a4cd-2741cf401d84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb43df3-7b89-4dcc-a135-0f4e7ca9d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Module):\n",
    "    def __init__(self, in_channels, num_filters, output_size):\n",
    "        super(Layer, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            Conv2d(in_channels=in_channels, out_channels=num_filters[0], kernel_size=(1, 1)),\n",
    "            AdaptiveAvgPool2d(output_size=output_size),\n",
    "            Conv2d(in_channels=num_filters[0], out_channels=num_filters[1], kernel_size=(3, 3)),\n",
    "            AdaptiveAvgPool2d(output_size=output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b35ac8e-f25a-40b1-bfbc-417dbbbff557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer1x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer1x, self).__init__()\n",
    "        self.layer1 = Layer(64, [32, 64], (128, 128))\n",
    "        self.layer2 = Layer(64, [32, 64], (128, 128))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "    \n",
    "class Layer2x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer2x, self).__init__()\n",
    "        self.layer1 = Layer(128, [64, 128], (64, 64))\n",
    "        self.layer2 = Layer(128, [64, 128], (64, 64))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "    \n",
    "    \n",
    "class Layer8x_1st(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer8x_1st, self).__init__()\n",
    "        self.layer1 = Layer(256, [128, 256], (32, 32))\n",
    "        self.layer2 = Layer(256, [128, 256], (32, 32))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "class Layer8x_2nd(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer8x_2nd, self).__init__()\n",
    "        self.layer1 = Layer(512, [256, 512], (16, 16))\n",
    "        self.layer2 = Layer(512, [256, 512], (16, 16))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "class Layer4x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Layer4x, self).__init__()\n",
    "        self.layer1 = Layer(1024, [512, 1024], (8, 8))\n",
    "        self.layer2 = Layer(1024, [512, 1024], (8, 8))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x += residual\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26fa94ce-855d-467f-9d71-3bd2089c5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes:int = 1000):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Sequential(\n",
    "                Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(256, 256)),\n",
    "                Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(128, 128))\n",
    "            ),\n",
    "            Layer1x(),\n",
    "            nn.Sequential(\n",
    "                Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(64, 64))\n",
    "            ),\n",
    "            Layer2x(),\n",
    "            Layer2x(),\n",
    "            nn.Sequential(\n",
    "                Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(32, 32))\n",
    "            ),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            Layer8x_1st(),\n",
    "            nn.Sequential(\n",
    "                Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(16, 16))\n",
    "            ),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            Layer8x_2nd(),\n",
    "            nn.Sequential(\n",
    "                Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3)),\n",
    "                ReLU(inplace=True),\n",
    "                AdaptiveAvgPool2d(output_size=(16, 16))\n",
    "            ),\n",
    "            Layer4x(),\n",
    "            Layer4x(),\n",
    "            Layer4x(),\n",
    "            Layer4x()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            Linear(8*8*1024, num_classes),\n",
    "            Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1eed991-4c9b-4066-b1c8-6f10e7bb1122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): AdaptiveAvgPool2d(output_size=(256, 256))\n",
       "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): AdaptiveAvgPool2d(output_size=(128, 128))\n",
       "    )\n",
       "    (1): Layer1x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(128, 128))\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(128, 128))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(128, 128))\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(128, 128))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "    )\n",
       "    (3): Layer2x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Layer2x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "    )\n",
       "    (6): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Layer8x_1st(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(32, 32))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "    )\n",
       "    (15): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): Layer8x_2nd(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "          (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "    )\n",
       "    (24): Layer4x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (25): Layer4x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (26): Layer4x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (27): Layer4x(\n",
       "      (layer1): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "      (layer2): Layer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "          (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=65536, out_features=18, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = MyModel(num_classes=18)\n",
    "# torch.save(my_model, \"./my_model_210825_15h34m\")\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60b01746-27c9-43f8-9b13-e9f09a1c2cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9005109816ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-bba75c7e9bdc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-d7b5ab729d3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(32, 3, 1024, 1024))\n",
    "my_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f363ddf-0c82-464d-9500-ff729997b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9208ed1-7224-4052-a488-e3701e3cbaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 8, 9])\n",
      "torch.Size([1, 64, 5, 7])\n",
      "========================================\n",
      "torch.Size([1, 64, 10, 9])\n",
      "torch.Size([1, 64, 7, 7])\n",
      "========================================\n",
      "torch.Size([1, 64, 10, 9])\n",
      "torch.Size([1, 64, 10, 7])\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# target output size of 5x7\n",
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "input_ = torch.randn(1, 64, 8, 9)\n",
    "output = m(input_)\n",
    "print(input_.size())\n",
    "print(output.size())\n",
    "print(\"=\"*40)\n",
    "# target output size of 7x7 (square)\n",
    "m = nn.AdaptiveAvgPool2d(7)\n",
    "input_ = torch.randn(1, 64, 10, 9)\n",
    "output = m(input_)\n",
    "print(input_.size())\n",
    "print(output.size())\n",
    "print(\"=\"*40)\n",
    "# target output size of 10x7\n",
    "m = nn.AdaptiveAvgPool2d((None, 7))\n",
    "input_ = torch.randn(1, 64, 10, 9)\n",
    "output = m(input_)\n",
    "print(input_.size())\n",
    "print(output.size())\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d94f381d-a57b-4100-a9a5-c3f07a1f5508",
   "metadata": {},
   "source": [
    "AlexNet(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (7): ReLU(inplace=True)\n",
    "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): ReLU(inplace=True)\n",
    "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (11): ReLU(inplace=True)\n",
    "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
    "  (classifier): Sequential(\n",
    "    (0): Dropout(p=0.5, inplace=False)\n",
    "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): Dropout(p=0.5, inplace=False)\n",
    "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (5): ReLU(inplace=True)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94e4e9-2d32-4a14-902d-4b20ee1e08b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b31f5f9-ba73-4226-8b61-2d1205a45c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "752b8479-1902-4225-9f14-44bf7f48fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84cb5f05-6176-48f4-a76f-dc19b1d05a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in alexnet.named_modules():\n",
    "    if name == \"classifier.6\":\n",
    "        module.out_features = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40efdc9d-2d83-4d64-90b6-6731e12245ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c6fef46-dbbd-4571-99fb-2183477b3c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "features\n",
      "features.0\n",
      "features.1\n",
      "features.2\n",
      "features.3\n",
      "features.4\n",
      "features.5\n",
      "features.6\n",
      "features.7\n",
      "features.8\n",
      "features.9\n",
      "features.10\n",
      "features.11\n",
      "features.12\n",
      "avgpool\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.1\n",
      "classifier.2\n",
      "classifier.3\n",
      "classifier.4\n",
      "classifier.5\n",
      "classifier.6\n"
     ]
    }
   ],
   "source": [
    "for name, module in alexnet.named_modules():\n",
    "    for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if \"classifier.6\" in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8edf766-9755-447a-ac94-ce8e5e10e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight  ----  True\n",
      "========================================\n",
      "features.0.bias  ----  True\n",
      "========================================\n",
      "features.3.weight  ----  True\n",
      "========================================\n",
      "features.3.bias  ----  True\n",
      "========================================\n",
      "features.6.weight  ----  True\n",
      "========================================\n",
      "features.6.bias  ----  True\n",
      "========================================\n",
      "features.8.weight  ----  True\n",
      "========================================\n",
      "features.8.bias  ----  True\n",
      "========================================\n",
      "features.10.weight  ----  True\n",
      "========================================\n",
      "features.10.bias  ----  True\n",
      "========================================\n",
      "classifier.1.weight  ----  True\n",
      "========================================\n",
      "classifier.1.bias  ----  True\n",
      "========================================\n",
      "classifier.4.weight  ----  True\n",
      "========================================\n",
      "classifier.4.bias  ----  True\n",
      "========================================\n",
      "classifier.6.weight  ----  True\n",
      "========================================\n",
      "classifier.6.bias  ----  True\n",
      "========================================\n",
      "0.weight  ----  True\n",
      "========================================\n",
      "0.bias  ----  True\n",
      "========================================\n",
      "3.weight  ----  True\n",
      "========================================\n",
      "3.bias  ----  True\n",
      "========================================\n",
      "6.weight  ----  True\n",
      "========================================\n",
      "6.bias  ----  True\n",
      "========================================\n",
      "8.weight  ----  True\n",
      "========================================\n",
      "8.bias  ----  True\n",
      "========================================\n",
      "10.weight  ----  True\n",
      "========================================\n",
      "10.bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "1.weight  ----  True\n",
      "========================================\n",
      "1.bias  ----  True\n",
      "========================================\n",
      "4.weight  ----  True\n",
      "========================================\n",
      "4.bias  ----  True\n",
      "========================================\n",
      "6.weight  ----  True\n",
      "========================================\n",
      "6.bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n",
      "weight  ----  True\n",
      "========================================\n",
      "bias  ----  True\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for name, module in alexnet.named_modules():\n",
    "    for param_name, param in module.named_parameters():\n",
    "        print(param_name, \" ---- \", param.requires_grad)\n",
    "        print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "114a1322-99db-42cb-bc20-069c398c5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(alexnet, \"./alexnet_before_fine_tune_210825_18h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ccf11-dcae-49ea-b372-98a568015254",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea0d43e-d445-44e8-8f3d-0df6bbe404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be6467b-0c2d-481d-9552-f90a1b1ee459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80aaa4d1-0844-4d84-a134-fdf2e508fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in resnet18.named_modules():\n",
    "    if name == \"fc\":\n",
    "        module.out_features = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85edf70-4570-49fb-a3a3-4384d32c40cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=18, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in resnet18.named_modules():\n",
    "    if name == \"fc\":\n",
    "        print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69f62d4c-df68-4eb8-9332-0df565c73410",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18, \"resnet18_before_fine_tune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d8606-23f6-4043-8f64-7a4ce2d030af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa2014b-945f-4e76-85fb-2aa52cd9698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_inception_v3, bat_resnext26ts, botnet26t_256, botnet50ts_256, cait_m36_384, \n",
      "cait_m48_448, cait_s24_224, cait_s24_384, cait_s36_384, cait_xs24_384, \n",
      "cait_xxs24_224, cait_xxs24_384, cait_xxs36_224, cait_xxs36_384, coat_lite_mini, \n",
      "coat_lite_small, coat_lite_tiny, coat_mini, coat_tiny, convit_base, \n",
      "convit_small, convit_tiny, cspdarknet53, cspdarknet53_iabn, cspresnet50, \n",
      "cspresnet50d, cspresnet50w, cspresnext50, cspresnext50_iabn, darknet53, \n",
      "deit_base_distilled_patch16_224, deit_base_distilled_patch16_384, deit_base_patch16_224, deit_base_patch16_384, deit_small_distilled_patch16_224, \n",
      "deit_small_patch16_224, deit_tiny_distilled_patch16_224, deit_tiny_patch16_224, densenet121, densenet121d, \n",
      "densenet161, densenet169, densenet201, densenet264, densenet264d_iabn, \n",
      "densenetblur121d, dla34, dla46_c, dla46x_c, dla60, \n",
      "dla60_res2net, dla60_res2next, dla60x, dla60x_c, dla102, \n",
      "dla102x, dla102x2, dla169, dm_nfnet_f0, dm_nfnet_f1, \n",
      "dm_nfnet_f2, dm_nfnet_f3, dm_nfnet_f4, dm_nfnet_f5, dm_nfnet_f6, \n",
      "dpn68, dpn68b, dpn92, dpn98, dpn107, \n",
      "dpn131, eca_botnext26ts_256, eca_efficientnet_b0, eca_halonext26ts, eca_lambda_resnext26ts, \n",
      "eca_nfnet_l0, eca_nfnet_l1, eca_nfnet_l2, eca_nfnet_l3, eca_swinnext26ts_256, \n",
      "eca_vovnet39b, ecaresnet26t, ecaresnet50d, ecaresnet50d_pruned, ecaresnet50t, \n",
      "ecaresnet101d, ecaresnet101d_pruned, ecaresnet200d, ecaresnet269d, ecaresnetlight, \n",
      "ecaresnext26t_32x4d, ecaresnext50t_32x4d, efficientnet_b0, efficientnet_b1, efficientnet_b1_pruned, \n",
      "efficientnet_b2, efficientnet_b2_pruned, efficientnet_b2a, efficientnet_b3, efficientnet_b3_pruned, \n",
      "efficientnet_b3a, efficientnet_b4, efficientnet_b5, efficientnet_b6, efficientnet_b7, \n",
      "efficientnet_b8, efficientnet_cc_b0_4e, efficientnet_cc_b0_8e, efficientnet_cc_b1_8e, efficientnet_el, \n",
      "efficientnet_el_pruned, efficientnet_em, efficientnet_es, efficientnet_es_pruned, efficientnet_l2, \n",
      "efficientnet_lite0, efficientnet_lite1, efficientnet_lite2, efficientnet_lite3, efficientnet_lite4, \n",
      "efficientnetv2_l, efficientnetv2_m, efficientnetv2_rw_m, efficientnetv2_rw_s, efficientnetv2_s, \n",
      "ens_adv_inception_resnet_v2, ese_vovnet19b_dw, ese_vovnet19b_slim, ese_vovnet19b_slim_dw, ese_vovnet39b, \n",
      "ese_vovnet39b_evos, ese_vovnet57b, ese_vovnet99b, ese_vovnet99b_iabn, fbnetc_100, \n",
      "fbnetv3_b, fbnetv3_d, fbnetv3_g, gc_efficientnet_b0, gcresnet50t, \n",
      "gcresnext26ts, geresnet50t, gernet_l, gernet_m, gernet_s, \n",
      "ghostnet_050, ghostnet_100, ghostnet_130, gluon_inception_v3, gluon_resnet18_v1b, \n",
      "gluon_resnet34_v1b, gluon_resnet50_v1b, gluon_resnet50_v1c, gluon_resnet50_v1d, gluon_resnet50_v1s, \n",
      "gluon_resnet101_v1b, gluon_resnet101_v1c, gluon_resnet101_v1d, gluon_resnet101_v1s, gluon_resnet152_v1b, \n",
      "gluon_resnet152_v1c, gluon_resnet152_v1d, gluon_resnet152_v1s, gluon_resnext50_32x4d, gluon_resnext101_32x4d, \n",
      "gluon_resnext101_64x4d, gluon_senet154, gluon_seresnext50_32x4d, gluon_seresnext101_32x4d, gluon_seresnext101_64x4d, \n",
      "gluon_xception65, gmixer_12_224, gmixer_24_224, gmlp_b16_224, gmlp_s16_224, \n",
      "gmlp_ti16_224, halonet26t, halonet50ts, halonet_h1, halonet_h1_c4c5, \n",
      "hardcorenas_a, hardcorenas_b, hardcorenas_c, hardcorenas_d, hardcorenas_e, \n",
      "hardcorenas_f, hrnet_w18, hrnet_w18_small, hrnet_w18_small_v2, hrnet_w30, \n",
      "hrnet_w32, hrnet_w40, hrnet_w44, hrnet_w48, hrnet_w64, \n",
      "ig_resnext101_32x8d, ig_resnext101_32x16d, ig_resnext101_32x32d, ig_resnext101_32x48d, inception_resnet_v2, \n",
      "inception_v3, inception_v4, lambda_resnet26t, lambda_resnet50t, legacy_senet154, \n",
      "legacy_seresnet18, legacy_seresnet34, legacy_seresnet50, legacy_seresnet101, legacy_seresnet152, \n",
      "legacy_seresnext26_32x4d, legacy_seresnext50_32x4d, legacy_seresnext101_32x4d, levit_128, levit_128s, \n",
      "levit_192, levit_256, levit_384, mixer_b16_224, mixer_b16_224_in21k, \n",
      "mixer_b16_224_miil, mixer_b16_224_miil_in21k, mixer_b32_224, mixer_l16_224, mixer_l16_224_in21k, \n",
      "mixer_l32_224, mixer_s16_224, mixer_s32_224, mixnet_l, mixnet_m, \n",
      "mixnet_s, mixnet_xl, mixnet_xxl, mnasnet_050, mnasnet_075, \n",
      "mnasnet_100, mnasnet_140, mnasnet_a1, mnasnet_b1, mnasnet_small, \n",
      "mobilenetv2_100, mobilenetv2_110d, mobilenetv2_120d, mobilenetv2_140, mobilenetv3_large_075, \n",
      "mobilenetv3_large_100, mobilenetv3_large_100_miil, mobilenetv3_large_100_miil_in21k, mobilenetv3_rw, mobilenetv3_small_075, \n",
      "mobilenetv3_small_100, nasnetalarge, nf_ecaresnet26, nf_ecaresnet50, nf_ecaresnet101, \n",
      "nf_regnet_b0, nf_regnet_b1, nf_regnet_b2, nf_regnet_b3, nf_regnet_b4, \n",
      "nf_regnet_b5, nf_resnet26, nf_resnet50, nf_resnet101, nf_seresnet26, \n",
      "nf_seresnet50, nf_seresnet101, nfnet_f0, nfnet_f0s, nfnet_f1, \n",
      "nfnet_f1s, nfnet_f2, nfnet_f2s, nfnet_f3, nfnet_f3s, \n",
      "nfnet_f4, nfnet_f4s, nfnet_f5, nfnet_f5s, nfnet_f6, \n",
      "nfnet_f6s, nfnet_f7, nfnet_f7s, nfnet_l0, pit_b_224, \n",
      "pit_b_distilled_224, pit_s_224, pit_s_distilled_224, pit_ti_224, pit_ti_distilled_224, \n",
      "pit_xs_224, pit_xs_distilled_224, pnasnet5large, rednet26t, rednet50ts, \n",
      "regnetx_002, regnetx_004, regnetx_006, regnetx_008, regnetx_016, \n",
      "regnetx_032, regnetx_040, regnetx_064, regnetx_080, regnetx_120, \n",
      "regnetx_160, regnetx_320, regnety_002, regnety_004, regnety_006, \n",
      "regnety_008, regnety_016, regnety_032, regnety_040, regnety_064, \n",
      "regnety_080, regnety_120, regnety_160, regnety_320, repvgg_a2, \n",
      "repvgg_b0, repvgg_b1, repvgg_b1g4, repvgg_b2, repvgg_b2g4, \n",
      "repvgg_b3, repvgg_b3g4, res2net50_14w_8s, res2net50_26w_4s, res2net50_26w_6s, \n",
      "res2net50_26w_8s, res2net50_48w_2s, res2net101_26w_4s, res2next50, resmlp_12_224, \n",
      "resmlp_12_distilled_224, resmlp_24_224, resmlp_24_distilled_224, resmlp_36_224, resmlp_36_distilled_224, \n",
      "resmlp_big_24_224, resmlp_big_24_224_in22ft1k, resmlp_big_24_distilled_224, resnest14d, resnest26d, \n",
      "resnest50d, resnest50d_1s4x24d, resnest50d_4s2x40d, resnest101e, resnest200e, \n",
      "resnest269e, resnet18, resnet18d, resnet26, resnet26d, \n",
      "resnet26t, resnet34, resnet34d, resnet50, resnet50d, \n",
      "resnet50t, resnet51q, resnet61q, resnet101, resnet101d, \n",
      "resnet152, resnet152d, resnet200, resnet200d, resnetblur18, \n",
      "resnetblur50, resnetrs50, resnetrs101, resnetrs152, resnetrs200, \n",
      "resnetrs270, resnetrs350, resnetrs420, resnetv2_50, resnetv2_50d, \n",
      "resnetv2_50t, resnetv2_50x1_bit_distilled, resnetv2_50x1_bitm, resnetv2_50x1_bitm_in21k, resnetv2_50x3_bitm, \n",
      "resnetv2_50x3_bitm_in21k, resnetv2_101, resnetv2_101d, resnetv2_101x1_bitm, resnetv2_101x1_bitm_in21k, \n",
      "resnetv2_101x3_bitm, resnetv2_101x3_bitm_in21k, resnetv2_152, resnetv2_152d, resnetv2_152x2_bit_teacher, \n",
      "resnetv2_152x2_bit_teacher_384, resnetv2_152x2_bitm, resnetv2_152x2_bitm_in21k, resnetv2_152x4_bitm, resnetv2_152x4_bitm_in21k, \n",
      "resnext50_32x4d, resnext50d_32x4d, resnext101_32x4d, resnext101_32x8d, resnext101_64x4d, \n",
      "rexnet_100, rexnet_130, rexnet_150, rexnet_200, rexnetr_100, \n",
      "rexnetr_130, rexnetr_150, rexnetr_200, selecsls42, selecsls42b, \n",
      "selecsls60, selecsls60b, selecsls84, semnasnet_050, semnasnet_075, \n",
      "semnasnet_100, semnasnet_140, senet154, seresnet18, seresnet34, \n",
      "seresnet50, seresnet50t, seresnet101, seresnet152, seresnet152d, \n",
      "seresnet200d, seresnet269d, seresnext26d_32x4d, seresnext26t_32x4d, seresnext26tn_32x4d, \n",
      "seresnext50_32x4d, seresnext101_32x4d, seresnext101_32x8d, skresnet18, skresnet34, \n",
      "skresnet50, skresnet50d, skresnext50_32x4d, spnasnet_100, ssl_resnet18, \n",
      "ssl_resnet50, ssl_resnext50_32x4d, ssl_resnext101_32x4d, ssl_resnext101_32x8d, ssl_resnext101_32x16d, \n",
      "swin_base_patch4_window7_224, swin_base_patch4_window7_224_in22k, swin_base_patch4_window12_384, swin_base_patch4_window12_384_in22k, swin_large_patch4_window7_224, \n",
      "swin_large_patch4_window7_224_in22k, swin_large_patch4_window12_384, swin_large_patch4_window12_384_in22k, swin_small_patch4_window7_224, swin_tiny_patch4_window7_224, \n",
      "swinnet26t_256, swinnet50ts_256, swsl_resnet18, swsl_resnet50, swsl_resnext50_32x4d, \n",
      "swsl_resnext101_32x4d, swsl_resnext101_32x8d, swsl_resnext101_32x16d, tf_efficientnet_b0, tf_efficientnet_b0_ap, \n",
      "tf_efficientnet_b0_ns, tf_efficientnet_b1, tf_efficientnet_b1_ap, tf_efficientnet_b1_ns, tf_efficientnet_b2, \n",
      "tf_efficientnet_b2_ap, tf_efficientnet_b2_ns, tf_efficientnet_b3, tf_efficientnet_b3_ap, tf_efficientnet_b3_ns, \n",
      "tf_efficientnet_b4, tf_efficientnet_b4_ap, tf_efficientnet_b4_ns, tf_efficientnet_b5, tf_efficientnet_b5_ap, \n",
      "tf_efficientnet_b5_ns, tf_efficientnet_b6, tf_efficientnet_b6_ap, tf_efficientnet_b6_ns, tf_efficientnet_b7, \n",
      "tf_efficientnet_b7_ap, tf_efficientnet_b7_ns, tf_efficientnet_b8, tf_efficientnet_b8_ap, tf_efficientnet_cc_b0_4e, \n",
      "tf_efficientnet_cc_b0_8e, tf_efficientnet_cc_b1_8e, tf_efficientnet_el, tf_efficientnet_em, tf_efficientnet_es, \n",
      "tf_efficientnet_l2_ns, tf_efficientnet_l2_ns_475, tf_efficientnet_lite0, tf_efficientnet_lite1, tf_efficientnet_lite2, \n",
      "tf_efficientnet_lite3, tf_efficientnet_lite4, tf_efficientnetv2_b0, tf_efficientnetv2_b1, tf_efficientnetv2_b2, \n",
      "tf_efficientnetv2_b3, tf_efficientnetv2_l, tf_efficientnetv2_l_in21ft1k, tf_efficientnetv2_l_in21k, tf_efficientnetv2_m, \n",
      "tf_efficientnetv2_m_in21ft1k, tf_efficientnetv2_m_in21k, tf_efficientnetv2_s, tf_efficientnetv2_s_in21ft1k, tf_efficientnetv2_s_in21k, \n",
      "tf_inception_v3, tf_mixnet_l, tf_mixnet_m, tf_mixnet_s, tf_mobilenetv3_large_075, \n",
      "tf_mobilenetv3_large_100, tf_mobilenetv3_large_minimal_100, tf_mobilenetv3_small_075, tf_mobilenetv3_small_100, tf_mobilenetv3_small_minimal_100, \n",
      "tnt_b_patch16_224, tnt_s_patch16_224, tresnet_l, tresnet_l_448, tresnet_m, \n",
      "tresnet_m_448, tresnet_m_miil_in21k, tresnet_xl, tresnet_xl_448, tv_densenet121, \n",
      "tv_resnet34, tv_resnet50, tv_resnet101, tv_resnet152, tv_resnext50_32x4d, \n",
      "twins_pcpvt_base, twins_pcpvt_large, twins_pcpvt_small, twins_svt_base, twins_svt_large, \n",
      "twins_svt_small, vgg11, vgg11_bn, vgg13, vgg13_bn, \n",
      "vgg16, vgg16_bn, vgg19, vgg19_bn, visformer_small, \n",
      "visformer_tiny, vit_base_patch16_224, vit_base_patch16_224_in21k, vit_base_patch16_224_miil, vit_base_patch16_224_miil_in21k, \n",
      "vit_base_patch16_384, vit_base_patch32_224, vit_base_patch32_224_in21k, vit_base_patch32_384, vit_base_r26_s32_224, \n",
      "vit_base_r50_s16_224, vit_base_r50_s16_224_in21k, vit_base_r50_s16_384, vit_base_resnet26d_224, vit_base_resnet50_224_in21k, \n",
      "vit_base_resnet50_384, vit_base_resnet50d_224, vit_huge_patch14_224_in21k, vit_large_patch16_224, vit_large_patch16_224_in21k, \n",
      "vit_large_patch16_384, vit_large_patch32_224, vit_large_patch32_224_in21k, vit_large_patch32_384, vit_large_r50_s32_224, \n",
      "vit_large_r50_s32_224_in21k, vit_large_r50_s32_384, vit_small_patch16_224, vit_small_patch16_224_in21k, vit_small_patch16_384, \n",
      "vit_small_patch32_224, vit_small_patch32_224_in21k, vit_small_patch32_384, vit_small_r26_s32_224, vit_small_r26_s32_224_in21k, \n",
      "vit_small_r26_s32_384, vit_small_resnet26d_224, vit_small_resnet50d_s16_224, vit_tiny_patch16_224, vit_tiny_patch16_224_in21k, \n",
      "vit_tiny_patch16_384, vit_tiny_r_s16_p8_224, vit_tiny_r_s16_p8_224_in21k, vit_tiny_r_s16_p8_384, vovnet39a, \n",
      "vovnet57a, wide_resnet50_2, wide_resnet101_2, xception, xception41, \n",
      "xception65, xception71, "
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(timm.list_models(), start=1):\n",
    "    print(name, end=\", \")\n",
    "    if i % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbff990-946f-442f-a2ae-f2e75685a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convit_base, convit_small, convit_tiny, levit_128, levit_128s, \n",
      "levit_192, levit_256, levit_384, vit_base_patch16_224, vit_base_patch16_224_in21k, \n",
      "vit_base_patch16_224_miil, vit_base_patch16_224_miil_in21k, vit_base_patch16_384, vit_base_patch32_224, vit_base_patch32_224_in21k, \n",
      "vit_base_patch32_384, vit_base_r26_s32_224, vit_base_r50_s16_224, vit_base_r50_s16_224_in21k, vit_base_r50_s16_384, \n",
      "vit_base_resnet26d_224, vit_base_resnet50_224_in21k, vit_base_resnet50_384, vit_base_resnet50d_224, vit_huge_patch14_224_in21k, \n",
      "vit_large_patch16_224, vit_large_patch16_224_in21k, vit_large_patch16_384, vit_large_patch32_224, vit_large_patch32_224_in21k, \n",
      "vit_large_patch32_384, vit_large_r50_s32_224, vit_large_r50_s32_224_in21k, vit_large_r50_s32_384, vit_small_patch16_224, \n",
      "vit_small_patch16_224_in21k, vit_small_patch16_384, vit_small_patch32_224, vit_small_patch32_224_in21k, vit_small_patch32_384, \n",
      "vit_small_r26_s32_224, vit_small_r26_s32_224_in21k, vit_small_r26_s32_384, vit_small_resnet26d_224, vit_small_resnet50d_s16_224, \n",
      "vit_tiny_patch16_224, vit_tiny_patch16_224_in21k, vit_tiny_patch16_384, vit_tiny_r_s16_p8_224, vit_tiny_r_s16_p8_224_in21k, \n",
      "vit_tiny_r_s16_p8_384, "
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(timm.list_models(\"*vit*\"), start=1):\n",
    "    print(name, end=\", \")\n",
    "    if i % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f1c04-d2ce-4c15-8cf2-be647f1bb16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2667f-aad1-4c0e-87a2-b93de99fd5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a9833-5adf-4f58-9042-e1db7d90d104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b684-3f66-4392-9c12-95cc58fcf13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765dfa8-3ad7-49e6-96ad-03290f52ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceCrop(torch.nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "#         self.size = _setup_size(size, error_msg=\"Please provide only two dimensions (h, w) for size.\")\n",
    "        self.size = size\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = np.array(img)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        bbox = face_cascade.detectMultiScale(img)\n",
    "        if len(bbox) != 0:\n",
    "            return F.crop(img, *bbox)\n",
    "        else:\n",
    "            return F.center_crop(img, self.size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5e0f7-25d5-45c0-a3d0-472487eeb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceCrop(object):\n",
    "    \"\"\"Crop face area of the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        assert isinstance(size, (int, tuple))\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
