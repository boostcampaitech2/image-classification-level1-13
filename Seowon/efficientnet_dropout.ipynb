{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geographic-foster",
   "metadata": {
    "id": "geographic-foster"
   },
   "source": [
    "# Lesson 4 - Data Generation\n",
    "- 이번 실습자료에서는 파이토치 모델에 이미지를 입력값으로 주기위해 전처리를 하는 방법을 배웁니다.\n",
    "- 파이토치는 torch.utils.data에 있는 Dataset, DataLoader 클래스가 이 작업을 간편하게 해줍니다.\n",
    "## 0. Libraries & Configurations\n",
    "- 시각화에 필요한 라이브러리와 데이터 경로를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occasional-boxing",
   "metadata": {
    "id": "occasional-boxing"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d2c989-10ec-40e0-9fb3-39cfe0c7dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f359add-e895-4ee5-bad5-7587b81fdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complex-israel",
   "metadata": {
    "id": "complex-israel"
   },
   "outputs": [],
   "source": [
    "### Configurations\n",
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "df_path = f'{data_dir}/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "whole-computer",
   "metadata": {
    "id": "whole-computer"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender   race  age                    path\n",
       "0  000001  female  Asian   45  000001_female_Asian_45\n",
       "1  000002  female  Asian   52  000002_female_Asian_52\n",
       "2  000004    male  Asian   54    000004_male_Asian_54\n",
       "3  000005  female  Asian   58  000005_female_Asian_58\n",
       "4  000006  female  Asian   59  000006_female_Asian_59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-operation",
   "metadata": {
    "id": "compliant-operation"
   },
   "source": [
    "## 2. Dataset\n",
    "- 이 부분에서는 Dataset을 정의하는 방법을 간단하게 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-juvenile",
   "metadata": {
    "id": "democratic-juvenile"
   },
   "source": [
    "## 2.1 Augmentation Function\n",
    "- 3강에서 배운 Augmentation 함수를 정의합니다.\n",
    "- mean, std는 임의로 설정하였으나 파트 1에서 계산한 값을 입력해도 괜찮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "horizontal-strain",
   "metadata": {
    "id": "horizontal-strain"
   },
   "outputs": [],
   "source": [
    "mean, std = (0.5, 0.5, 0.5), (0.2, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-recycling",
   "metadata": {
    "id": "distant-recycling"
   },
   "source": [
    "### 2.1.1 Torchvision Style Augmentation Function\n",
    "- Torchvision에서 제공되는 transforms를 이용한 Augmentation 함수입니다.\n",
    "- 이를 사용하여 Dataset을 정의하여도 괜찮지만, 이번 실습자료에서는 강의에서 배웠던 Albumentation을 활용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "current-hometown",
   "metadata": {
    "id": "current-hometown",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Torchvision-Style Transforms\\nfrom torchvision import transforms\\nfrom torchvision.transforms import Resize, ToTensor, Normalize, GaussianBlur, RandomRotation, ColorJitter\\n\\n\\nclass AddGaussianNoise(object):\\n    def __init__(self, mean=0., std=1.):\\n        self.std = std\\n        self.mean = mean\\n\\n    def __call__(self, tensor):\\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\\n\\n    def __repr__(self):\\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\\n\\n\\ndef get_transforms(need=('train', 'val'), img_size=(512, 384)):\\n    transformations = {}\\n    if 'train' in need:\\n        transformations['train'] = transforms.Compose([\\n            Resize((img_size[0], img_size[1])),\\n            RandomRotation([-8, +8]),\\n            GaussianBlur(51, (0.1, 2.0)),\\n            ColorJitter(brightness=0.5, saturation=0.5, hue=0.5),  # todo : param\\n            ToTensor(),\\n            Normalize(mean=mean, std=std),\\n            AddGaussianNoise(0., 1.)\\n        ])\\n    if 'val' in need:\\n        transformations['val'] = transforms.Compose([\\n            Resize((img_size[0], img_size[1])),\\n            ToTensor(),\\n            Normalize(mean=mean, std=std),\\n        ])\\n    return transformations\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Torchvision-Style Transforms\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, GaussianBlur, RandomRotation, ColorJitter\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384)):\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = transforms.Compose([\n",
    "            Resize((img_size[0], img_size[1])),\n",
    "            RandomRotation([-8, +8]),\n",
    "            GaussianBlur(51, (0.1, 2.0)),\n",
    "            ColorJitter(brightness=0.5, saturation=0.5, hue=0.5),  # todo : param\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "            AddGaussianNoise(0., 1.)\n",
    "        ])\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = transforms.Compose([\n",
    "            Resize((img_size[0], img_size[1])),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "    return transformations\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-survivor",
   "metadata": {
    "id": "sudden-survivor"
   },
   "source": [
    "### 2.1.2 Albumentation Style Augmentation Function\n",
    "- Albumentation은 numpy 형식으로 이미지를 받아 데이터를 변형시킵니다.\n",
    "- opencv 기반으로 빠르고, 다양한 Augmentation 방법이 제공되는 점에서 장점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "national-diameter",
   "metadata": {
    "id": "national-diameter"
   },
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 이부분 size 변경\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    \"\"\"\n",
    "    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n",
    "    \n",
    "    Args:\n",
    "        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n",
    "        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n",
    "        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n",
    "        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n",
    "\n",
    "    Returns:\n",
    "        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n",
    "    \"\"\"\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "#             HorizontalFlip(p=0.5),\n",
    "#             ShiftScaleRotate(p=0.5),\n",
    "#             HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "#             RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#             GaussNoise(p=0.5),\n",
    "            CenterCrop(308, 220, p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1]),\n",
    "            CenterCrop(308, 220, p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-lafayette",
   "metadata": {
    "id": "partial-lafayette"
   },
   "source": [
    "### 2.2 Define Dataset\n",
    "\n",
    "- 여기에서는 이미지와 레이블을 출력하는 Dataset 클래스를 정의합니다.\n",
    "- 레이블은 마스크 여부, 성별, 나이로 결정이 됩니다.\n",
    "- 레이블은 3(마스크 착용, 미착용, 잘못착용) * 2(남성, 여성) * 3(30세 미만, 30세-60세, 60세 이상) 으로 총 18개가 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "annoying-emission",
   "metadata": {
    "id": "annoying-emission"
   },
   "outputs": [],
   "source": [
    "### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n",
    "\n",
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "\n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 60 else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "divine-transmission",
   "metadata": {
    "id": "divine-transmission"
   },
   "outputs": [],
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1.jpg\": MaskLabels.mask,\n",
    "        \"mask2.jpg\": MaskLabels.mask,\n",
    "        \"mask3.jpg\": MaskLabels.mask,\n",
    "        \"mask4.jpg\": MaskLabels.mask,\n",
    "        \"mask5.jpg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n",
    "        \"normal.jpg\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name, label in self._file_names.items():\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(label)\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = getattr(GenderLabels, gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "secure-plasma",
   "metadata": {
    "id": "secure-plasma"
   },
   "outputs": [],
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = MaskBaseDataset(\n",
    "    img_dir=img_dir\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 95:5 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.05)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-membrane",
   "metadata": {
    "id": "regulation-membrane"
   },
   "source": [
    "## 3. DataLoader\n",
    "- 정의한 Dataset을 바탕으로 DataLoader을 생성합니다.\n",
    "- Dataset은 이미지 한장을 주는 모듈이라면, DataLoader은 여러 이미지를 batch_size만큼 묶어 전달해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "blessed-robert",
   "metadata": {
    "id": "blessed-robert"
   },
   "outputs": [],
   "source": [
    "# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-richardson",
   "metadata": {
    "id": "tracked-richardson"
   },
   "source": [
    "## 4.  Visualize Processed Data\n",
    "- 파트 4에선 정의한 DataLoader을 이용하여 데이터가 어떻게 전처리 되었는지 시각화하여 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "explicit-bathroom",
   "metadata": {
    "id": "explicit-bathroom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([32, 3, 308, 220])\n",
      "labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(f'images shape: {images.shape}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-reynolds",
   "metadata": {
    "id": "several-reynolds"
   },
   "outputs": [],
   "source": [
    "# from torchvision import transforms\n",
    "\n",
    "# # Augmentation으로 이미지를 Normalize했기 때문에, 역으로 다시 Normalize 해주어야합니다.\n",
    "# inv_normalize = transforms.Normalize(\n",
    "#     mean=[-m / s for m, s in zip(mean, std)],\n",
    "#     std=[1 / s for s in std]\n",
    "# )\n",
    "\n",
    "# n_rows, n_cols = 4, 3\n",
    "\n",
    "# fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(16, 24))\n",
    "# for i in range(n_rows*n_cols):\n",
    "#     axes[i%n_rows][i//(n_cols+1)].imshow(inv_normalize(images[i]).permute(1, 2, 0))\n",
    "#     axes[i%n_rows][i//(n_cols+1)].set_title(f'Label: {labels[i]}', color='r')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1c6c5-7554-4ab1-a437-6a04b0b3ec22",
   "metadata": {},
   "source": [
    "### <i>여기부터 추가</i>\n",
    "## 5. Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8330f805-1605-4dd2-8e97-7b8501eb10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# model.fc = nn.Linear(512, 18)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24b4e887-66aa-4045-9a6f-6754e51bc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91cc5f32-4f7e-441d-8379-c0a850390883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# timm_models = timm.list_models(\"*\")\n",
    "# for model in timm_models:\n",
    "#     print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe371a3-4368-4aa2-a9cf-42ad2a10e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in /opt/conda/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from efficientnet_pytorch) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be60ed95-d7f8-4337-bb96-fc5cca82f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from efficientnet_pytorch import EfficientNet\n",
    "# class efficientnet(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(efficientnet, self).__init__()\n",
    "#         self.conv2d = nn.Conv2d(3, 3, 3, stride=1)\n",
    "#         self.effnet = EfficientNet.from_pretrained('efficientnet-b0', dropout_rate=0.5) # 구조만 사용\n",
    "#         self.FC = nn.Linear(1000, 18)\n",
    "\n",
    "#         nn.init.xavier_normal_(self.FC.weight)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.silu(self.conv2d(x))\n",
    "\n",
    "#         # effnet을 추가\n",
    "#         x = F.silu(self.effnet(x))\n",
    "\n",
    "#         # 마지막 출력에 nn.Linear를 추가\n",
    "#         x = self.FC(x)\n",
    "#         return x\n",
    "\n",
    "# model = efficientnet()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8c183de-362e-4b0d-9a86-ac951ad8320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=18, dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "986a121f-088a-4985-b8c5-6d8a31e168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "dtype = torch.float\n",
    "ltype = torch.long # entropy\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e21f948-3ffb-4f5a-8dfe-678b84e5425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in /opt/conda/lib/python3.8/site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e712b7f1-484b-43a6-a8ff-8c30007949ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  8% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization() # iter마다 메모리 느는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da064e62-4a14-4c36-a0ad-ace74f35b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 29 04:37:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   47C    P0    39W / 250W |   2621MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c953a4-add4-4c44-9162-b5ed8e1efe32",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a93288b7-1d93-41ee-937e-c3b4dd59b806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ====================== epoch 1 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  8% |\n",
      "Iteration   0 | Train Loss  2.9090 | Classifier Accuracy 9.38\n",
      "Iteration  20 | Train Loss  1.0598 | Classifier Accuracy 71.88\n",
      "Iteration  40 | Train Loss  0.6037 | Classifier Accuracy 84.38\n",
      "Iteration  60 | Train Loss  0.3886 | Classifier Accuracy 90.62\n",
      "Iteration  80 | Train Loss  0.4313 | Classifier Accuracy 84.38\n",
      "Iteration 100 | Train Loss  0.5566 | Classifier Accuracy 87.50\n",
      "Iteration 120 | Train Loss  0.5176 | Classifier Accuracy 84.38\n",
      "Iteration 140 | Train Loss  0.3256 | Classifier Accuracy 87.50\n",
      "Iteration 160 | Train Loss  0.2534 | Classifier Accuracy 96.88\n",
      "Iteration 180 | Train Loss  0.5743 | Classifier Accuracy 78.12\n",
      "Iteration 200 | Train Loss  0.6343 | Classifier Accuracy 78.12\n",
      "Iteration 220 | Train Loss  0.1000 | Classifier Accuracy 96.88\n",
      "Iteration 240 | Train Loss  0.3284 | Classifier Accuracy 87.50\n",
      "Iteration 260 | Train Loss  0.4793 | Classifier Accuracy 81.25\n",
      "Iteration 280 | Train Loss  0.2843 | Classifier Accuracy 84.38\n",
      "Iteration 300 | Train Loss  0.1026 | Classifier Accuracy 96.88\n",
      "Iteration 320 | Train Loss  0.5970 | Classifier Accuracy 75.00\n",
      "Iteration 340 | Train Loss  0.4136 | Classifier Accuracy 87.50\n",
      "Iteration 360 | Train Loss  0.2599 | Classifier Accuracy 87.50\n",
      "Iteration 380 | Train Loss  0.3375 | Classifier Accuracy 87.50\n",
      "Iteration 400 | Train Loss  0.2438 | Classifier Accuracy 90.62\n",
      "Iteration 420 | Train Loss  0.2299 | Classifier Accuracy 90.62\n",
      "Iteration 440 | Train Loss  0.5062 | Classifier Accuracy 87.50\n",
      "Iteration 460 | Train Loss  0.2139 | Classifier Accuracy 96.88\n",
      "Iteration 480 | Train Loss  0.1051 | Classifier Accuracy 96.88\n",
      "Iteration 500 | Train Loss  0.0841 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.2737 | Classifier Accuracy 90.62\n",
      "\n",
      "[Summary] Elapsed time : 1 m 17 s\n",
      "Train Loss Mean 0.4541 | Accuracy 85.49 \n",
      "Valid Loss Mean 0.3171 | Accuracy 85.99 \n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 13% | 13% |\n",
      "Iteration   0 | Train Loss  0.2629 | Classifier Accuracy 90.62\n",
      "Iteration  20 | Train Loss  0.3776 | Classifier Accuracy 81.25\n",
      "Iteration  40 | Train Loss  0.1556 | Classifier Accuracy 96.88\n",
      "Iteration  60 | Train Loss  0.0739 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.2016 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0504 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0451 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.3886 | Classifier Accuracy 84.38\n",
      "Iteration 160 | Train Loss  0.3189 | Classifier Accuracy 90.62\n",
      "Iteration 180 | Train Loss  0.1841 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.1570 | Classifier Accuracy 90.62\n",
      "Iteration 220 | Train Loss  0.0560 | Classifier Accuracy 96.88\n",
      "Iteration 240 | Train Loss  0.4059 | Classifier Accuracy 78.12\n",
      "Iteration 260 | Train Loss  0.3821 | Classifier Accuracy 90.62\n",
      "Iteration 280 | Train Loss  0.0973 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.3710 | Classifier Accuracy 90.62\n",
      "Iteration 320 | Train Loss  0.2225 | Classifier Accuracy 93.75\n",
      "Iteration 340 | Train Loss  0.4441 | Classifier Accuracy 81.25\n",
      "Iteration 360 | Train Loss  0.0923 | Classifier Accuracy 96.88\n",
      "Iteration 380 | Train Loss  0.0775 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0632 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.1479 | Classifier Accuracy 96.88\n",
      "Iteration 440 | Train Loss  0.2754 | Classifier Accuracy 87.50\n",
      "Iteration 460 | Train Loss  0.2279 | Classifier Accuracy 90.62\n",
      "Iteration 480 | Train Loss  0.0787 | Classifier Accuracy 96.88\n",
      "Iteration 500 | Train Loss  0.0704 | Classifier Accuracy 96.88\n",
      "Iteration 520 | Train Loss  0.0288 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 36 s\n",
      "Train Loss Mean 0.1884 | Accuracy 93.28 \n",
      "Valid Loss Mean 0.2075 | Accuracy 90.84 \n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 41% | 21% |\n",
      "Iteration   0 | Train Loss  0.2362 | Classifier Accuracy 90.62\n",
      "Iteration  20 | Train Loss  0.2129 | Classifier Accuracy 96.88\n",
      "Iteration  40 | Train Loss  0.1798 | Classifier Accuracy 93.75\n",
      "Iteration  60 | Train Loss  0.0808 | Classifier Accuracy 96.88\n",
      "Iteration  80 | Train Loss  0.2270 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0594 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.1496 | Classifier Accuracy 96.88\n",
      "Iteration 140 | Train Loss  0.1198 | Classifier Accuracy 93.75\n",
      "Iteration 160 | Train Loss  0.0871 | Classifier Accuracy 96.88\n",
      "Iteration 180 | Train Loss  0.0217 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0501 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.1263 | Classifier Accuracy 93.75\n",
      "Iteration 240 | Train Loss  0.2152 | Classifier Accuracy 90.62\n",
      "Iteration 260 | Train Loss  0.2043 | Classifier Accuracy 90.62\n",
      "Iteration 280 | Train Loss  0.1912 | Classifier Accuracy 90.62\n",
      "Iteration 300 | Train Loss  0.1841 | Classifier Accuracy 93.75\n",
      "Iteration 320 | Train Loss  0.0639 | Classifier Accuracy 96.88\n",
      "Iteration 340 | Train Loss  0.0518 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0557 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0730 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.1921 | Classifier Accuracy 90.62\n",
      "Iteration 420 | Train Loss  0.0933 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0894 | Classifier Accuracy 96.88\n",
      "Iteration 460 | Train Loss  0.0295 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0637 | Classifier Accuracy 96.88\n",
      "Iteration 500 | Train Loss  0.1138 | Classifier Accuracy 96.88\n",
      "Iteration 520 | Train Loss  0.0732 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 12 s\n",
      "Train Loss Mean 0.1188 | Accuracy 95.90 \n",
      "Valid Loss Mean 0.2348 | Accuracy 91.38 \n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 37% | 21% |\n",
      "Iteration   0 | Train Loss  0.1319 | Classifier Accuracy 93.75\n",
      "Iteration  20 | Train Loss  0.0512 | Classifier Accuracy 96.88\n",
      "Iteration  40 | Train Loss  0.0904 | Classifier Accuracy 93.75\n",
      "Iteration  60 | Train Loss  0.0124 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0574 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0143 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0102 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0534 | Classifier Accuracy 96.88\n",
      "Iteration 160 | Train Loss  0.0515 | Classifier Accuracy 96.88\n",
      "Iteration 180 | Train Loss  0.1624 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0042 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0511 | Classifier Accuracy 96.88\n",
      "Iteration 240 | Train Loss  0.0482 | Classifier Accuracy 96.88\n",
      "Iteration 260 | Train Loss  0.0124 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0121 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0242 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0264 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0414 | Classifier Accuracy 96.88\n",
      "Iteration 360 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0101 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0078 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0698 | Classifier Accuracy 96.88\n",
      "Iteration 440 | Train Loss  0.0169 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0229 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0226 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.1723 | Classifier Accuracy 96.88\n",
      "Iteration 520 | Train Loss  0.0020 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 36 s\n",
      "Train Loss Mean 0.0387 | Accuracy 98.72 \n",
      "Valid Loss Mean 0.0383 | Accuracy 95.91 \n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 12% | 21% |\n",
      "Iteration   0 | Train Loss  0.0067 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0173 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.1114 | Classifier Accuracy 96.88\n",
      "Iteration  60 | Train Loss  0.0038 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.1024 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0609 | Classifier Accuracy 96.88\n",
      "Iteration 120 | Train Loss  0.0261 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0117 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0074 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0581 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0393 | Classifier Accuracy 96.88\n",
      "Iteration 240 | Train Loss  0.0062 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0451 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0610 | Classifier Accuracy 96.88\n",
      "Iteration 320 | Train Loss  0.0077 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0015 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0076 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0055 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0169 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0060 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0105 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0059 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0096 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0101 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0021 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 40 s\n",
      "Train Loss Mean 0.0178 | Accuracy 99.42 \n",
      "Valid Loss Mean 0.0305 | Accuracy 96.12 \n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 21% |\n",
      "Iteration   0 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0218 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0284 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0171 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0111 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0086 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0034 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0040 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0012 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0064 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0018 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0022 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0043 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0064 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0012 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0148 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0032 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0038 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0024 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0148 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0140 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0106 | Accuracy 99.68 \n",
      "Valid Loss Mean 0.0193 | Accuracy 96.55 \n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 33% | 21% |\n",
      "Iteration   0 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0074 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0020 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0081 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0127 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0792 | Classifier Accuracy 96.88\n",
      "Iteration 120 | Train Loss  0.0005 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0197 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0232 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0041 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0022 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0023 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0042 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0066 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0418 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0013 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0096 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0027 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 15 s\n",
      "Train Loss Mean 0.0092 | Accuracy 99.71 \n",
      "Valid Loss Mean 0.0188 | Accuracy 96.34 \n",
      "\n",
      " ====================== epoch 8 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 21% | 21% |\n",
      "Iteration   0 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0134 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0071 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0032 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0081 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0021 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0446 | Classifier Accuracy 96.88\n",
      "Iteration 160 | Train Loss  0.0023 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0074 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0021 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0051 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0050 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0042 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0047 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0039 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0067 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0024 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0122 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0083 | Accuracy 99.73 \n",
      "Valid Loss Mean 0.0200 | Accuracy 96.34 \n",
      "\n",
      " ====================== epoch 9 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 21% | 21% |\n",
      "Iteration   0 | Train Loss  0.0127 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0015 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0020 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0565 | Classifier Accuracy 96.88\n",
      "Iteration 140 | Train Loss  0.0046 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0050 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0015 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0324 | Classifier Accuracy 96.88\n",
      "Iteration 240 | Train Loss  0.0075 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0123 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0047 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0007 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0199 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0006 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0005 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0064 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0170 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0047 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0093 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 22 s\n",
      "Train Loss Mean 0.0081 | Accuracy 99.70 \n",
      "Valid Loss Mean 0.0199 | Accuracy 96.34 \n",
      "\n",
      " ====================== epoch 10 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 21% |\n",
      "Iteration   0 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0208 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0193 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0023 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0035 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0012 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0222 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0130 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0449 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0132 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0041 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0087 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0090 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0018 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0063 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0008 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0136 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0065 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0013 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 2 m 14 s\n",
      "Train Loss Mean 0.0074 | Accuracy 99.73 \n",
      "Valid Loss Mean 0.0191 | Accuracy 96.44 \n",
      "\n",
      " ====================== epoch 11 ======================\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 96% | 62% |\n",
      "Iteration   0 | Train Loss  0.0091 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0035 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0051 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0043 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0039 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0015 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0057 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0065 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0058 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0189 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0055 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0101 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0060 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0114 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0146 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0058 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0018 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0003 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 2 m 19 s\n",
      "Train Loss Mean 0.0074 | Accuracy 99.74 \n",
      "Valid Loss Mean 0.0196 | Accuracy 96.44 \n",
      "\n",
      " ====================== epoch 12 ======================\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 83% |\n",
      "Iteration   0 | Train Loss  0.0057 | Classifier Accuracy 100.00\n",
      "Iteration  20 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration  40 | Train Loss  0.0036 | Classifier Accuracy 100.00\n",
      "Iteration  60 | Train Loss  0.0048 | Classifier Accuracy 100.00\n",
      "Iteration  80 | Train Loss  0.0023 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0133 | Classifier Accuracy 100.00\n",
      "Iteration 120 | Train Loss  0.0046 | Classifier Accuracy 100.00\n",
      "Iteration 140 | Train Loss  0.0005 | Classifier Accuracy 100.00\n",
      "Iteration 160 | Train Loss  0.0042 | Classifier Accuracy 100.00\n",
      "Iteration 180 | Train Loss  0.0032 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 220 | Train Loss  0.0079 | Classifier Accuracy 100.00\n",
      "Iteration 240 | Train Loss  0.0132 | Classifier Accuracy 100.00\n",
      "Iteration 260 | Train Loss  0.0022 | Classifier Accuracy 100.00\n",
      "Iteration 280 | Train Loss  0.0058 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 320 | Train Loss  0.0033 | Classifier Accuracy 100.00\n",
      "Iteration 340 | Train Loss  0.0012 | Classifier Accuracy 100.00\n",
      "Iteration 360 | Train Loss  0.0039 | Classifier Accuracy 100.00\n",
      "Iteration 380 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 420 | Train Loss  0.0032 | Classifier Accuracy 100.00\n",
      "Iteration 440 | Train Loss  0.0014 | Classifier Accuracy 100.00\n",
      "Iteration 460 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration 480 | Train Loss  0.0042 | Classifier Accuracy 100.00\n",
      "Iteration 500 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration 520 | Train Loss  0.0025 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 2 m 30 s\n",
      "Train Loss Mean 0.0077 | Accuracy 99.73 \n",
      "Valid Loss Mean 0.0200 | Accuracy 96.34 \n",
      "\n",
      "EARLY STOPPING!!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "valid_early_stop = 0\n",
    "valid_best_loss = float('inf')\n",
    "EARLY_STOPPING_EPOCH = 5\n",
    "since = time.time()\n",
    "\n",
    "final_train_loss = []\n",
    "final_train_acc = []\n",
    "final_valid_loss = []\n",
    "final_valid_acc = []\n",
    "\n",
    "for e in range(num_epochs) :\n",
    "    print(f' ====================== epoch %d ======================' % (e+1) )\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    GPUtil.showUtilization()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, (images, targets) in enumerate(train_loader) : \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device, dtype)\n",
    "        targets = targets.to(device, ltype)\n",
    "\n",
    "        scores = model(images)\n",
    "        _, preds = scores.max(dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = sum(targets == preds).cpu()\n",
    "        acc=(correct/32 * 100)\n",
    "\n",
    "        train_loss_list.append(loss.tolist())\n",
    "        train_acc_list.append(acc.tolist())\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print(f'Iteration %3.d | Train Loss  %.4f | Classifier Accuracy %2.2f' % (i, loss, acc))\n",
    "\n",
    "    train_mean_loss = np.mean(train_loss_list, dtype=\"float64\")\n",
    "    train_mean_acc = np.mean(train_acc_list, dtype=\"float64\")\n",
    "\n",
    "    final_train_loss.append(train_mean_loss.tolist())\n",
    "    final_train_acc.append(train_mean_acc.tolist())\n",
    "\n",
    "    epoch_time = time.time() - since\n",
    "    since = time.time()\n",
    "\n",
    "    print('')\n",
    "    print(f'[Summary] Elapsed time : %.0f m %.0f s' % (epoch_time // 60, epoch_time % 60))\n",
    "    print(f'Train Loss Mean %.4f | Accuracy %2.2f ' % (train_mean_loss, train_mean_acc) )\n",
    "\n",
    "    # validation \n",
    "    valid_loss_list = []\n",
    "    valid_acc_list = []\n",
    "    model.eval()\n",
    "    for i, (images, targets) in enumerate(val_loader) : \n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device=device, dtype=dtype)\n",
    "        targets = targets.to(device=device, dtype=ltype)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = model(images)\n",
    "            loss = F.cross_entropy(scores, targets)\n",
    "            _, preds = scores.max(dim=1)\n",
    "\n",
    "        correct = sum(targets == preds).cpu()\n",
    "        acc=(correct/32 * 100)\n",
    "\n",
    "        valid_loss_list.append(loss.tolist())\n",
    "        valid_acc_list.append(acc.tolist())\n",
    "\n",
    "    val_mean_loss = np.mean(valid_loss_list, dtype=\"float64\")\n",
    "    val_mean_acc = np.mean(valid_acc_list, dtype=\"float64\")\n",
    "\n",
    "    final_valid_loss.append(val_mean_loss.tolist())\n",
    "    final_valid_acc.append(val_mean_acc.tolist())\n",
    "\n",
    "    print(f'Valid Loss Mean %.4f | Accuracy %2.2f ' % (val_mean_loss, val_mean_acc) )\n",
    "    print('')\n",
    "\n",
    "    if val_mean_loss < valid_best_loss:\n",
    "        valid_best_loss = val_mean_loss\n",
    "        valid_early_stop = 0\n",
    "        # new best model save (valid 기준)\n",
    "        best_model = model\n",
    "\n",
    "    else:\n",
    "        # early stopping    \n",
    "        valid_early_stop += 1\n",
    "        if valid_early_stop >= EARLY_STOPPING_EPOCH:\n",
    "            print(\"EARLY STOPPING!!\")\n",
    "            break\n",
    "\n",
    "    lr_sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d17de209-94be-4213-a98c-c8f1f4afdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ee3c1d7-ba04-4dcf-b41d-cf65d7e20118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "# transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "# dataset = MaskBaseDataset(\n",
    "#     img_dir=img_dir\n",
    "# )\n",
    "\n",
    "# # train dataset과 validation dataset을 9:1 비율로 나눕니다.\n",
    "# n_val = int(len(dataset) * 0.1)\n",
    "# n_train = len(dataset) - n_val\n",
    "# train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# # 각 dataset에 augmentation 함수를 설정합니다.\n",
    "# train_dataset.dataset.set_transform(transform['train'])\n",
    "# val_dataset.dataset.set_transform(transform['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d66e37f2-5b82-491b-a7cb-5ca86bb69f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, CenterCrop\n",
    "\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    CenterCrop((308, 220)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "# transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "# dataset = MaskBaseDataset(\n",
    "#     img_dir=test_dir\n",
    "# )\n",
    "\n",
    "# dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = best_model\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device=device, dtype=dtype)\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, '0829_submission_efficientb0_dropout.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afece8-fe68-474f-a853-1867b80be649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_DataGeneration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
